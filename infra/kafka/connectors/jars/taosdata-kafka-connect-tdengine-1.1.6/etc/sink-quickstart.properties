# A simple example that copies from a topic to a TDengine database.
# The first few settings are required for all connectors:
# a name, the connector class to run, and the maximum number of tasks to create:
name=tdengine-sink
connector.class=com.taosdata.kafka.connect.sink.TDengineSinkConnector
tasks.max=1

# The topics to consume from - required for sink connectors like this one
topics=schemaless

# Configuration specific to the JDBC sink connector.
# We want to connect to a TDengine database stored in the file test.db and auto-create tables.

connection.url=jdbc:TAOS://127.0.0.1:6030
connection.user=root
connection.password=taosdata
connection.database=sink
connection.attempts=3
connection.backoff.ms=5000
connection.database.prefix=kafka_

max.retries=3
retry.backoff.ms=3000
batch.size=1000
db.charset=UTF-8
db.timeunit=milliseconds
db.schemaless=line
data.precision=

key.converter=org.apache.kafka.connect.storage.StringConverter
value.converter=org.apache.kafka.connect.storage.StringConverter